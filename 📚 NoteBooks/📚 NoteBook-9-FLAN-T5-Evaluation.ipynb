{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670a70ea",
   "metadata": {},
   "source": [
    "# üìö NoteBook 10 FLAN-T5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130295c4",
   "metadata": {},
   "source": [
    "# üöÄ PROJECT PLAN\n",
    "\n",
    "MKEM Implementation ‚Äì Transformer-Based Abstractive Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10984e",
   "metadata": {},
   "source": [
    "# üéØ Problem Statement Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6c4be",
   "metadata": {},
   "source": [
    "# üîç Objective:\n",
    "    \n",
    "To build and compare transformer-based summarization models (T5, BART, Pegasus,BARTScore,ProphetNet,BigBird,LED,mTS,FLAN-T5,GPT 3.5 Turbo) and then enhance them using MKEM (Multi-Knowledge-Enhanced Model) on curated English news datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e29815",
   "metadata": {},
   "source": [
    "# üìå Phase-1 Objective\n",
    "\n",
    "‚úÖ Implement the following 3 summarization models:\n",
    "\n",
    "PEGASUS (Google)---NoteBook(2)\n",
    "\n",
    "BART (Facebook)---NoteBook(3)\n",
    "\n",
    "T5 (Google)---NoteBook(1)\n",
    "\n",
    "Final Comparison + MKEM---NoteBook(4)\n",
    "\n",
    "NewsSum(Indian Newspaper)---NoteBook(5)\n",
    "\n",
    "BARTScore---NoteBook(6)\n",
    "\n",
    "ProphetNet---NoteBook(7)\n",
    "\n",
    "BigBird-Pegasus---NoteBook(8)\n",
    "\n",
    "LED(Longformer)---NoteBook(9)\n",
    "\n",
    "allenai/PRIMERA ---NoteBook(10)\n",
    "\n",
    "FLAN-T5---NoteBook(11)\n",
    "\n",
    "GPT-3.5 Turbo---NoteBook(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aee56b",
   "metadata": {},
   "source": [
    "# ‚úÖ Evaluate on 3 benchmark datasets:\n",
    "    \n",
    "CNN/DailyMail\n",
    "\n",
    "Newssum (IndianNewsPaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d958d",
   "metadata": {},
   "source": [
    "# ‚úÖ Evaluation Metrics:\n",
    "\n",
    "ROUGE-1\n",
    "\n",
    "ROUGE-2\n",
    "\n",
    "ROUGE-L\n",
    "\n",
    "BERTScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee555e70",
   "metadata": {},
   "source": [
    "# üìä Final Output (Per Model √ó Dataset):\n",
    "    \n",
    "You must submit structured results:\n",
    "\n",
    "Dataset name\n",
    "\n",
    "Model used\n",
    "\n",
    "ROUGE-1, ROUGE-2, ROUGE-L, BERTScore\n",
    "\n",
    "Inference Time\n",
    "\n",
    "GPU used\n",
    "\n",
    "Short analysis/observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1164d1e",
   "metadata": {},
   "source": [
    "# 1.üöÄ FLAN-T5  on CNN Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6d93d",
   "metadata": {},
   "source": [
    "**‚úèÔ∏èStep 1: Install & Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661ba27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMIM IMTIAZ\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "import time\n",
    "import evaluate\n",
    "import bert_score\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7d5c5",
   "metadata": {},
   "source": [
    "**‚úèÔ∏è Step 2: Load Model & Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de29ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded google/flan-t5-base\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"  # Faster than large\n",
    "\n",
    "tokenizer_flan = AutoTokenizer.from_pretrained(model_name)\n",
    "model_flan = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "print(f\"‚úÖ Loaded {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b1a06",
   "metadata": {},
   "source": [
    "**‚úèÔ∏è Step 3: Load CNN Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c26f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CNN Dataset Loaded. Shape: (5, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets ¬£20M f...</td>\n",
       "      <td>42c027e4ff9730fbb3de84c1af0d2c506e41c3e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
       "      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
       "      <td>06352019a19ae31e527f37f7571c6dd7f0c5da37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
       "      <td>Five small polyps found during procedure; \"non...</td>\n",
       "      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)  -- The National Football League has ind...</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
       "      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  LONDON, England (Reuters) -- Harry Potter star...   \n",
       "1  Editor's note: In our Behind the Scenes series...   \n",
       "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
       "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
       "4  (CNN)  -- The National Football League has ind...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Harry Potter star Daniel Radcliffe gets ¬£20M f...   \n",
       "1  Mentally ill inmates in Miami are housed on th...   \n",
       "2  NEW: \"I thought I was going to die,\" driver sa...   \n",
       "3  Five small polyps found during procedure; \"non...   \n",
       "4  NEW: NFL chief, Atlanta Falcons owner critical...   \n",
       "\n",
       "                                         id  \n",
       "0  42c027e4ff9730fbb3de84c1af0d2c506e41c3e4  \n",
       "1  ee8871b15c50d0db17b0179a6d2beab35065f1e9  \n",
       "2  06352019a19ae31e527f37f7571c6dd7f0c5da37  \n",
       "3  24521a2abb2e1f5e34e6824e0f9e56904a2b0e88  \n",
       "4  7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned CNN dataset (from Notebook 1)\n",
    "df_cnn = pd.read_csv(\"cnn_dailymail.csv\")\n",
    "\n",
    "# Drop missing or empty articles/highlights\n",
    "df_cnn = df_cnn.dropna(subset=[\"article\", \"highlights\"])\n",
    "df_cnn = df_cnn[df_cnn[\"article\"].str.strip().astype(bool)]\n",
    "\n",
    "print(f\"‚úÖ CNN Dataset Loaded. Shape: {df_cnn.shape}\")\n",
    "df_cnn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8157d6",
   "metadata": {},
   "source": [
    "**‚úèÔ∏è Step 4: Define Summarization Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592bcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_flan(text):\n",
    "    inputs = tokenizer_flan(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    summary_ids = model_flan.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=150,\n",
    "        min_length=40,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4\n",
    "    )\n",
    "    return tokenizer_flan.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ddcec",
   "metadata": {},
   "source": [
    "**‚úèÔ∏è Step 5: Generate Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e773db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è± Inference Time: 139.93 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "flan_cnn_preds = [summarize_with_flan(article) for article in df_cnn[\"article\"]]\n",
    "flan_cnn_refs = df_cnn[\"highlights\"].tolist()\n",
    "inference_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"‚è± Inference Time: {inference_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308eec6",
   "metadata": {},
   "source": [
    "**‚úèÔ∏è Step 6: Evaluate with ROUGE & BERTScore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2ee42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# After generating flan_cnn_preds and flan_cnn_refs\n",
    "del model_flan\n",
    "del tokenizer_flan\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa347fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\SAMIM IMTIAZ\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# ROUGE\n",
    "rouge_results = rouge.compute(predictions=flan_cnn_preds, references=flan_cnn_refs)\n",
    "\n",
    "# BERTScore\n",
    "bert_results = bertscore.compute(predictions=flan_cnn_preds, references=flan_cnn_refs, lang=\"en\")\n",
    "bert_f1 = round(sum(bert_results[\"f1\"]) / len(bert_results[\"f1\"]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed271e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "# Load metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# ROUGE\n",
    "rouge_results = rouge.compute(predictions=flan_cnn_preds, references=flan_cnn_refs)\n",
    "\n",
    "# BERTScore\n",
    "bert_results = bertscore.compute(predictions=flan_cnn_preds, references=flan_cnn_refs, lang=\"en\")\n",
    "bert_f1 = round(sum(bert_results[\"f1\"]) / len(bert_results[\"f1\"]), 4)\n",
    "\n",
    "# Create result dictionary\n",
    "flan_cnn_scores = {\n",
    "    \"Dataset\": [\"CNN\"],\n",
    "    \"Model\": [\"FLAN-T5\"],\n",
    "    \"ROUGE-1\": [rouge_results[\"rouge1\"]],\n",
    "    \"ROUGE-2\": [rouge_results[\"rouge2\"]],\n",
    "    \"ROUGE-L\": [rouge_results[\"rougeL\"]],\n",
    "    \"BERTScore\": [bert_f1],\n",
    "    \"Inference Time (s)\": [inference_time],\n",
    "    \"GPU Used\": [torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae23a83",
   "metadata": {},
   "source": [
    "**üíæ Save the Scores to .CSV Files**\n",
    "\n",
    "**So that we can use to comapair models in different NoteBooks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ee96c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FLAN-T5 CNN scores saved to flan_cnn_scores.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "      <th>GPU Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>FLAN-T5</td>\n",
       "      <td>0.220208</td>\n",
       "      <td>0.046759</td>\n",
       "      <td>0.142072</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>139.93</td>\n",
       "      <td>CPU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset    Model   ROUGE-1   ROUGE-2   ROUGE-L  BERTScore  \\\n",
       "0     CNN  FLAN-T5  0.220208  0.046759  0.142072     0.8456   \n",
       "\n",
       "   Inference Time (s) GPU Used  \n",
       "0              139.93      CPU  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flan_cnn_scores_df = pd.DataFrame(flan_cnn_scores)\n",
    "\n",
    "# Save CSV\n",
    "flan_cnn_scores_df.to_csv(\"flan_cnn_scores.csv\", index=False)\n",
    "print(\"‚úÖ FLAN-T5 CNN scores saved to flan_cnn_scores.csv\")\n",
    "\n",
    "flan_cnn_scores_df\n",
    "\n",
    "# Display result in table format\n",
    "#from tabulate import tabulate\n",
    "#print(tabulate(flan_cnn_scores_df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33859c9",
   "metadata": {},
   "source": [
    "# 2.üöÄ FLAN-T5 on NewsSum Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6452e56",
   "metadata": {},
   "source": [
    "**‚úèÔ∏è Step 1: Load NewsSum Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a8d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NewsSum dataset loaded. Shape: (1003, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load NewsSum dataset\n",
    "df_newsum = pd.read_csv(\"newsum_cleaned.csv\")\n",
    "\n",
    "# Prepare reference summaries\n",
    "flan_newsum_refs = df_newsum[\"Summary\"].tolist()\n",
    "\n",
    "print(f\"‚úÖ NewsSum dataset loaded. Shape: {df_newsum.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b850b2",
   "metadata": {},
   "source": [
    "**‚úèÔ∏èStep 2: Generate Summaries with FLAN-T5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fa90b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded google/flan-t5-base\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"google/flan-t5-base\"  # or flan-t5-large if you want bigger model\n",
    "tokenizer_flan = AutoTokenizer.from_pretrained(model_name)\n",
    "model_flan = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "print(f\"‚úÖ Loaded {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9856b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è± Inference Time (NewsSum - FLAN-T5, 5 rows): 213.29 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ‚úÖ Limit to 5 rows for quick test\n",
    "df_newsum_small = df_newsum.iloc[:5].copy()\n",
    "flan_newsum_refs = df_newsum_small[\"Summary\"].tolist()\n",
    "\n",
    "# Run summarization\n",
    "start_time = time.time()\n",
    "flan_newsum_preds = [summarize_with_flan(article) for article in df_newsum_small[\"Article\"]]\n",
    "inference_time = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"‚è± Inference Time (NewsSum - FLAN-T5, 5 rows): {inference_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf29a5",
   "metadata": {},
   "source": [
    "**‚úèÔ∏èStep 3: Evaluate with ROUGE and BERTScore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799fd30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMIM IMTIAZ\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ROUGE\n",
    "rouge_results = rouge.compute(predictions=flan_newsum_preds, references=flan_newsum_refs)\n",
    "\n",
    "# BERTScore\n",
    "bert_results = bertscore.compute(predictions=flan_newsum_preds, references=flan_newsum_refs, lang=\"en\")\n",
    "bert_f1 = round(sum(bert_results[\"f1\"]) / len(bert_results[\"f1\"]), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8959d",
   "metadata": {},
   "source": [
    "**üíæ Step 4: Save Evaluation Scores to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4d32ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FLAN-T5 NewsSum scores saved to flan_newsum_scores.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "      <th>GPU Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NewsSum</td>\n",
       "      <td>FLAN-T5</td>\n",
       "      <td>0.38682</td>\n",
       "      <td>0.277672</td>\n",
       "      <td>0.318049</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>213.29</td>\n",
       "      <td>CPU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset    Model  ROUGE-1   ROUGE-2   ROUGE-L  BERTScore  \\\n",
       "0  NewsSum  FLAN-T5  0.38682  0.277672  0.318049     0.8765   \n",
       "\n",
       "   Inference Time (s) GPU Used  \n",
       "0              213.29      CPU  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flan_newsum_scores = {\n",
    "    \"Dataset\": [\"NewsSum\"],\n",
    "    \"Model\": [\"FLAN-T5\"],\n",
    "    \"ROUGE-1\": [rouge_results[\"rouge1\"]],\n",
    "    \"ROUGE-2\": [rouge_results[\"rouge2\"]],\n",
    "    \"ROUGE-L\": [rouge_results[\"rougeL\"]],\n",
    "    \"BERTScore\": [bert_f1],\n",
    "    \"Inference Time (s)\": [inference_time],\n",
    "    \"GPU Used\": [torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"]\n",
    "}\n",
    "\n",
    "flan_newsum_scores_df = pd.DataFrame(flan_newsum_scores)\n",
    "\n",
    "# Save file\n",
    "flan_newsum_scores_df.to_csv(\"flan_newsum_scores.csv\", index=False)\n",
    "print(\"‚úÖ FLAN-T5 NewsSum scores saved to flan_newsum_scores.csv\")\n",
    "flan_newsum_scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
